{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c28b7ca8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Dataset overview\n",
    "- users.csv: Customer information\n",
    "- orders.csv: Transaction history\n",
    "- subscriptions.csv: Subscription data\n",
    "- preferences.csv: Customer taste preferences\n",
    "- events.scv: User behavioral events (page views, cart actions)\n",
    "- voucher_application: Voucher usage data\n",
    "- user_references.csv: Referral tracking\n",
    "- products.csv: Product catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48278774",
   "metadata": {},
   "source": [
    "## Key Question\n",
    "- Understand what are different groups among current customer base. \n",
    "- How do they differ? What are their needs? \n",
    "- What are the implications for the marketing strategy in terms of attracting similar new customers and/or retaining current customers?\n",
    "- How can these insights be used to recommend QLab Tea’s next action for user growth?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a863bf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_WARNINGS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642eb23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c8a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "\n",
    "if FILTER_WARNINGS:\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.set_loglevel('warning')\n",
    "\n",
    "\n",
    "logging.info(\"Setup completed successfully\")\n",
    "logging.debug(\"Using ENV variables:\")\n",
    "logging.debug(f\"FILTER_WARNINGS: {FILTER_WARNINGS}\")\n",
    "logging.warning(\"This is a warning message.\")\n",
    "logging.error(\"This is an error message.\")\n",
    "logging.critical(\"This is a critical message.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0047a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug(\"Loading datasets\")\n",
    "\n",
    "try:\n",
    "    users_df = pd.read_csv(\"./original_data/users.csv\")\n",
    "    orders_df = pd.read_csv(\"./original_data/orders.csv\")\n",
    "    subscriptions_df = pd.read_csv(\"./original_data/subscriptions.csv\")\n",
    "    products_df = pd.read_csv(\"./original_data/products.csv\")\n",
    "\n",
    "    preferences_df = pd.read_csv(\"./original_data/preferences.csv\")\n",
    "    events_df = pd.read_csv(\"./original_data/events.csv\")\n",
    "    voucher_applications_df = pd.read_csv(\"./original_data/voucher_applications.csv\")\n",
    "    user_references_df = pd.read_csv(\"./original_data/user_references.csv\")\n",
    "\n",
    "    logging.info(f\"Users: {len(users_df):,} rows\")\n",
    "    logging.info(f\"Orders: {len(orders_df):,} rows\")\n",
    "    logging.info(f\"Subscriptions: {len(subscriptions_df):,} rows\")\n",
    "    logging.info(f\"Products: {len(products_df):,} rows\")\n",
    "    logging.info(f\"Preferences: {len(preferences_df):,} rows\")\n",
    "    logging.info(f\"Events: {len(events_df):,} rows\")\n",
    "    logging.info(f\"Voucher Application: {len(voucher_applications_df):,} rows\")\n",
    "    logging.info(f\"User References: {len(user_references_df):,} rows\")\n",
    "except FileNotFoundError as e:\n",
    "    logging.error(f\"Error csv not found: {e}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    logging.critical(f\"Load csv error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8568203",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(users_df.head())\n",
    "display(orders_df.head())\n",
    "display(events_df.head())\n",
    "display(subscriptions_df.head())\n",
    "logging.debug(users_df.groupby(\"country\").count())\n",
    "logging.debug(subscriptions_df.groupby(\"currency\").count())\n",
    "logging.debug(orders_df.groupby(\"currency\").count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7d0ee2",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a63d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = {\n",
    "    \"Users\": users_df.isnull().sum(),\n",
    "    \"Orders\": orders_df.isnull().sum(),\n",
    "    \"Subscriptions\": subscriptions_df.isnull().sum(),\n",
    "    \"Products\": products_df.isnull().sum(),\n",
    "    \"Preferences\": preferences_df.isnull().sum(),\n",
    "    \"Events\": events_df.isnull().sum(),\n",
    "    \"Voucher Application\": voucher_applications_df.isnull().sum(),\n",
    "    \"User References\": user_references_df.isnull().sum(),\n",
    "}\n",
    "\n",
    "for k, v in missing_values.items():\n",
    "    logging.debug(f\"{k}\")\n",
    "    logging.debug(f\"{v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca14e1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_clean_df = users_df.copy()\n",
    "del users_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2700f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_rate = {\n",
    "    \"SGD\": 1.0,\n",
    "    \"HKD\": 0.17,\n",
    "    \"MYR\": 0.31,\n",
    "}\n",
    "\n",
    "\n",
    "orders_clean_df = orders_df.copy()\n",
    "# Only keep completed orders\n",
    "orders_clean_df = orders_clean_df[orders_clean_df[\"status\"].isin([\"Shipped\", \"Delivered\"])]\n",
    "# Remove <=0 order totals\n",
    "orders_clean_df = orders_clean_df[orders_clean_df[\"total_incl_tax\"]>0]\n",
    "# Fix dates\n",
    "orders_clean_df[\"date_placed\"] = pd.to_datetime(orders_clean_df[\"date_placed\"], errors=\"coerce\")\n",
    "orders_clean_df = orders_clean_df.dropna(subset=[\"date_placed\", \"user_id\"])\n",
    "\n",
    "logging.debug(f\"Cleaned orders: {len(orders_clean_df):,} rows\")\n",
    "logging.debug(f\"Date range: {orders_clean_df['date_placed'].min()} - {orders_clean_df['date_placed'].max()}\")\n",
    "logging.debug(f\"Total revenue: {orders_clean_df['total_incl_tax'].sum():.3f}\")\n",
    "\n",
    "def parse_order_items(order_items_json):\n",
    "    try:\n",
    "        items = json.loads(order_items_json)\n",
    "        num_items = sum(int(item.get(\"quantity\", 1)) for item in items)\n",
    "        product_ids = [item.get(\"product_id\") for item in items]\n",
    "        return pd.Series({\n",
    "            \"num_items\": num_items,\n",
    "            \"product_ids\": product_ids\n",
    "        })\n",
    "    except:\n",
    "        return pd.Series({\"num_items\": 1, \"product_ids\": []})\n",
    "    \n",
    "order_items_parsed = orders_clean_df['order_items'].apply(parse_order_items)\n",
    "orders_clean_df = pd.concat([orders_clean_df, order_items_parsed], axis=1)\n",
    "\n",
    "orders_clean_df[\"total_incl_tax_sgd\"] = (\n",
    "    orders_clean_df[\"total_incl_tax\"]\n",
    "    * orders_clean_df[\"currency\"].map(conversion_rate)\n",
    ")\n",
    "\n",
    "logging.debug(\"Order items parsing done\")\n",
    "logging.info(f\"Average item per order: {orders_clean_df['num_items'].mean():.2f}\")\n",
    "logging.debug(orders_clean_df[\"order_items\"][0])\n",
    "del orders_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0127a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscriptions_clean_df = subscriptions_df.copy()\n",
    "subscriptions_clean_df = subscriptions_clean_df.dropna(subset = [\"user_id\"])\n",
    "date_cols = [\"last_order\", \"next_order\", \"created\", \"updated\"]\n",
    "for col in date_cols:\n",
    "    subscriptions_clean_df[col] = pd.to_datetime(subscriptions_clean_df[col], errors=\"coerce\")\n",
    "del subscriptions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5d182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_clean_df = products_df.copy()\n",
    "del products_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dfeb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "preferences_clean_df = preferences_df.copy()\n",
    "preferences_clean_df = preferences_df.dropna(subset=[\"user_id\"])\n",
    "del preferences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867d4883",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_clean_df = events_df.copy()\n",
    "events_clean_df = events_clean_df.dropna(subset = [\"user_id\", \"timestamp\"])\n",
    "events_clean_df[\"timestamp\"] = pd.to_datetime(events_clean_df[\"timestamp\"], errors=\"coerce\")\n",
    "del events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a8c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "voucher_applications_clean_df = voucher_applications_df.copy()\n",
    "voucher_applications_clean_df = voucher_applications_clean_df.dropna(subset=[\"user_id\"])\n",
    "del voucher_applications_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564b19a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_references_clean_df = user_references_df.copy()\n",
    "del user_references_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5eb760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_values(df):\n",
    "    missing_summary = pd.DataFrame({\n",
    "        'Missing_Count': df.isnull().sum(),\n",
    "        'Missing_Percentage': (df.isnull().sum() / len(df)) * 100\n",
    "    }).sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "    logging.info(f\"\\n{missing_summary[missing_summary['Missing_Count'] > 0]}\\n\")\n",
    "\n",
    "# Recheck to see how we did for data cleaning\n",
    "cleaned_dfs = {\n",
    "    \"Users\": users_clean_df,\n",
    "    \"Orders\": orders_clean_df,\n",
    "    \"Subscriptions\": subscriptions_clean_df,\n",
    "    \"Products\": products_clean_df,\n",
    "    \"Preferences\": preferences_clean_df,\n",
    "    \"Events\": events_clean_df,\n",
    "    \"Voucher Application\": voucher_applications_clean_df,\n",
    "    \"User References\": user_references_clean_df,\n",
    "}\n",
    "\n",
    "for k, v in cleaned_dfs.items():\n",
    "    logging.info(f\"{k}\")\n",
    "    check_missing_values(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69598ca4",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b2d1eb",
   "metadata": {},
   "source": [
    "### 7 types of features\n",
    "1. RFM (Recency, Frequency, Monetary)\n",
    "2. Behavioral (purchase patterns)\n",
    "3. Product Category\n",
    "4. Subscription\n",
    "5. Engagement (from events)\n",
    "6. Promotion (voucher usage)\n",
    "7. Social (referrals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbb9bd1",
   "metadata": {},
   "source": [
    "#### RFM\n",
    "- recency_days = (reference_date - max(order_date)) for each customer\n",
    "- frequency_orders = count of orders per customer\n",
    "- monetary_total = sum of order totals amount per customer\n",
    "- avg_order_value = monetary_total/frequency_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e40c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "newest_date = orders_clean_df[\"date_placed\"].max()\n",
    "oldest_date = orders_clean_df[\"date_placed\"].min()\n",
    "\n",
    "logging.debug(f\"Reference date: {newest_date}\")\n",
    "\n",
    "# def sigmoid(x):\n",
    "#     return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# def sigmoid_series(series, steepness):\n",
    "#     series_range = series.max() - series.min() or pd.Timedelta(days=1)\n",
    "#     return sigmoid( \n",
    "#         steepness * (\n",
    "#         (\n",
    "#             (series - series.min()) / series_range\n",
    "#         ) \n",
    "#         - 0.5)\n",
    "#     )\n",
    "#\n",
    "# orders_clean_df[\"weighted_total_incl_tax_sgd\"] = (\n",
    "#     orders_clean_df[\"total_incl_tax_sgd\"]\n",
    "#     * sigmoid_series(orders_clean_df[\"date_placed\"], 12)\n",
    "# )\n",
    "\n",
    "def arbitrary_date_weights(dates):\n",
    "    year = dates.dt.year\n",
    "    return np.select(\n",
    "        [year <= 2019, year <= 2020, year <= 2021],\n",
    "        [0.2, 0.5, 0.8],\n",
    "        default=1.0,\n",
    "    )\n",
    "\n",
    "orders_clean_df[\"monetary_weight\"] = arbitrary_date_weights(orders_clean_df[\"date_placed\"])\n",
    "\n",
    "orders_clean_df[\"weighted_total_incl_tax_sgd\"] = (\n",
    "    orders_clean_df[\"total_incl_tax_sgd\"] * orders_clean_df[\"monetary_weight\"]\n",
    ")\n",
    "\n",
    "rfm_features = orders_clean_df.groupby(\"user_id\").agg(\n",
    "    {\n",
    "        \"date_placed\": [\n",
    "            lambda x: (newest_date - x.max()).days,                     # Recency\n",
    "            lambda x: len(x) / max((x.max() - x.min()).days, 1)         # Frequency\n",
    "        ],\n",
    "        \"weighted_total_incl_tax_sgd\": \"sum\" # Monetary\n",
    "    }\n",
    ").reset_index()\n",
    "\n",
    "rfm_features.columns = [\"user_id\", \"recency_days\", \"frequency_orders\", \"monetary_total\"]\n",
    "\n",
    "order_counts = orders_clean_df.groupby(\"user_id\")[\"id\"].count().rename(\"order_count\")\n",
    "rfm_features = rfm_features.join(order_counts, on=\"user_id\")\n",
    "\n",
    "rfm_features[\"avg_order_value\"] = (\n",
    "    rfm_features[\"monetary_total\"] / rfm_features[\"order_count\"].clip(lower=1)\n",
    ")\n",
    "\n",
    "rfm_features[\"avg_order_value\"] = rfm_features[\"monetary_total\"]/rfm_features[\"frequency_orders\"]\n",
    "\n",
    "\n",
    "logging.debug(f\"\\n{rfm_features.describe()}\")\n",
    "display(rfm_features.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a6638c",
   "metadata": {},
   "source": [
    "#### Behavioral\n",
    "- avg_items_per_order = Average number of items purchased per order\n",
    "- total_items = Total number of items ever purchased\n",
    "- num_addresses = Number of different shipping addresses (possible gifting or multi location)\n",
    "- primary_currency = Most commonly used currency\n",
    "- order_regularity_std = Standard deviation of days between orders (lower indicate regular purchases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5944e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavioral_features = orders_clean_df.groupby(\"user_id\").agg({\n",
    "    \"num_items\": [\"mean\", \"sum\"], # average number of items per order, total items\n",
    "    \"shipping_postal_code\": \"nunique\", # number of addresses\n",
    "    \"currency\": lambda x: x.mode()[0] if len(x.mode()) > 0 else \"SGD\", # Most common currency type\n",
    "    }\n",
    ").reset_index()\n",
    "\n",
    "behavioral_features.columns = [\"user_id\",\n",
    "                               \"avg_items_per_order\",\n",
    "                               \"total_items\",\n",
    "                               \"num_addresses\",\n",
    "                               \"primary_currency_behavioral\",\n",
    "                               #\"order_regularity_std\"\n",
    "                               ]\n",
    "\n",
    "def calc_order_regularity(user_orders):\n",
    "    if len(user_orders) < 2: return 0\n",
    "    dates = user_orders.sort_values(\"date_placed\")[\"date_placed\"]\n",
    "    days_between = dates.diff().dt.days.dropna()\n",
    "    return days_between.std() if len(days_between) > 0 else 0\n",
    "\n",
    "order_regularity = orders_clean_df.groupby(\"user_id\").apply(calc_order_regularity).reset_index()\n",
    "order_regularity.columns = [\"user_id\", \"order_regularity_std\"]\n",
    "\n",
    "behavioral_features = behavioral_features.merge(order_regularity, on=\"user_id\")\n",
    "\n",
    "logging.debug(f\"\\n{behavioral_features.describe()}\")\n",
    "logging.debug(f\"\\n{behavioral_features.head(10)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35492d02",
   "metadata": {},
   "source": [
    "#### Product Category\n",
    "- tea_pod_pct = Percentage of purchases that are tea pods\n",
    "- tea_bag_pct = Percentage of purchases that are tea bags\n",
    "- merchandise_pct = Percentage of purchases that are merchandise\n",
    "- bundle_pct = Percentage of purchases that are bundles/variety packs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd68239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Might need to check through this again to confirm\n",
    "\n",
    "def categorize_product(title):\n",
    "    title_lower = str(title).lower()\n",
    "\n",
    "    match_strings_pod = (\"teapods\", \"pods\")\n",
    "    match_strings_merch = (\"bag\", \"qlab\")\n",
    "    match_strings_subscription = (\"subscription\",)\n",
    "    match_strings_bundle = (\"bundle\", \"set\", \"pack\", \"variety\")\n",
    "\n",
    "    for keyterm in match_strings_pod:\n",
    "        if keyterm in title_lower:\n",
    "            return \"tea_pod\"\n",
    "    \n",
    "    for keyterm in match_strings_merch:\n",
    "        if keyterm in title_lower:\n",
    "            return \"merchandise\"\n",
    "        \n",
    "    for keyterm in match_strings_subscription:\n",
    "        if keyterm in title_lower:\n",
    "            return \"subscription\"\n",
    "    \n",
    "    for keyterm in match_strings_bundle:\n",
    "        if keyterm in title_lower:\n",
    "            return \"bundle\"\n",
    "        \n",
    "    return \"tea_bag\"\n",
    "\n",
    "products_clean_df[\"category\"] = products_clean_df[\"title\"].apply(categorize_product)\n",
    "logging.debug(products_clean_df[\"category\"].value_counts())\n",
    "\n",
    "def get_product_categories(product_ids_list):\n",
    "    if not isinstance(product_ids_list, list) or len(product_ids_list)==0: return []\n",
    "\n",
    "    categories = []\n",
    "    for pid in product_ids_list:\n",
    "        if pid is None:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            pid_int = int(pid)\n",
    "            matching_products = products_clean_df[products_clean_df[\"product_id\"]==pid_int]\n",
    "            if len(matching_products) > 0:\n",
    "                categories.append(matching_products.iloc[0][\"category\"])\n",
    "        except (ValueError, TypeError):\n",
    "            continue\n",
    "    return categories\n",
    "\n",
    "\n",
    "product_features_list = []\n",
    "total_customers = len(rfm_features)\n",
    "\n",
    "for idx, user_id in enumerate(rfm_features[\"user_id\"]):\n",
    "    if (idx+1) %1000 == 0:\n",
    "        logging.debug(f\"Processing {idx+1}/{total_customers} customers\")\n",
    "    user_orders = orders_clean_df[orders_clean_df[\"user_id\"] == user_id]\n",
    "\n",
    "    all_product_ids = []\n",
    "    for pids in user_orders[\"product_ids\"]:\n",
    "        if isinstance(pids, list):\n",
    "            all_product_ids.extend(pids)\n",
    "\n",
    "    categories = get_product_categories(all_product_ids)\n",
    "\n",
    "    total = len(categories) if len(categories) > 0 else 1\n",
    "\n",
    "    product_features_list.append({\n",
    "        \"user_id\": user_id,\n",
    "        \"tea_pod_pct\": (categories.count(\"tea_pod\") / total) * 100,\n",
    "        \"tea_bag_pct\": (categories.count(\"tea_bag\") / total) * 100,\n",
    "        \"merchandise_pct\": (categories.count(\"merchandise\") / total) * 100,\n",
    "        \"bundle_pct\": (categories.count(\"bundle\") / total) * 100\n",
    "        }\n",
    "    )\n",
    "\n",
    "product_features = pd.DataFrame(product_features_list)\n",
    "\n",
    "logging.debug(product_features.describe())\n",
    "display(product_features.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15545a4f",
   "metadata": {},
   "source": [
    "#### Subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315e21b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_features = subscriptions_clean_df.copy()\n",
    "\n",
    "subscription_features[\"is_active\"] = subscription_features[\"status\"].str.lower().eq(\"active\").astype(int)\n",
    "subscription_features[\"surprise_flag\"] = subscription_features[\"surprise\"].str.strip().str.lower().eq(\"yes\").astype(int)\n",
    "subscription_features[\"order_gap_days\"] = (subscription_features[\"next_order\"] - subscription_features[\"last_order\"]).dt.days\n",
    "subscription_features[\"subscription_age_days\"] = (pd.Timestamp(\"today\") - subscription_features[\"created\"]).dt.days\n",
    "\n",
    "# --- aggregate per user ---\n",
    "subscription_features = subscription_features.groupby(\"user_id\").agg(\n",
    "    total_subscription_records=(\"product_id\", \"count\"),\n",
    "    unique_products=(\"product_id\", \"nunique\"),\n",
    "    num_shipping_addresses=(\"shipping_postal_code\", \"nunique\"),\n",
    "    num_countries=(\"country\", \"nunique\"),\n",
    "    avg_interval=(\"interval\", \"mean\"),\n",
    "    interval_std=(\"interval\", \"std\"),\n",
    "    active_subscriptions=(\"is_active\", \"sum\"),\n",
    "    active_ratio=(\"is_active\", \"mean\"),\n",
    "    primary_shipping_method=(\"shipping_method\", lambda x: x.mode()[0] if len(x.mode()) else \"unknown\"),\n",
    "    primary_currency_subscription=(\"currency\", lambda x: x.mode()[0] if len(x.mode()) else \"SGD\"),\n",
    "    surprise_ratio=(\"surprise_flag\", \"mean\"),\n",
    "    avg_order_gap_days=(\"order_gap_days\", \"mean\"),\n",
    "    order_gap_std=(\"order_gap_days\", \"std\"),\n",
    "    avg_subscription_age_days=(\"subscription_age_days\", \"mean\"),\n",
    "    first_subscription_created=(\"created\", \"min\"),\n",
    "    latest_subscription_update=(\"updated\", \"max\"),\n",
    ").reset_index()\n",
    "\n",
    "logging.debug(f\"\\n{subscription_features.describe()}\")\n",
    "logging.debug(f\"\\n{subscription_features.head(10)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59528d8",
   "metadata": {},
   "source": [
    "#### Engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d760eb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug(events_clean_df.head(10))\n",
    "logging.debug(events_clean_df[\"event\"].unique())\n",
    "\n",
    "events_df = events_clean_df.copy()\n",
    "events_df[\"event_date\"] = events_df[\"timestamp\"].dt.date\n",
    "\n",
    "high_intent_events = {\n",
    "    \"ACTION_VIEW_PRODUCT\",\n",
    "    \"ACTION_ADD_ITEM_TO_CART\",\n",
    "    \"ACTION_VOUCHER_APPLY\",\n",
    "    \"PURCHASED_GIFT_CARD\",\n",
    "}\n",
    "\n",
    "events_df[\"is_high_intent\"] = events_df[\"event\"].isin(high_intent_events).astype(int)\n",
    "\n",
    "last_ts = events_df[\"timestamp\"].max().normalize()\n",
    "\n",
    "engagement_core = events_df.groupby(\"user_id\").agg(\n",
    "    total_events=(\"event\", \"count\"),\n",
    "    unique_event_types=(\"event\", \"nunique\"),\n",
    "    active_days=(\"event_date\", \"nunique\"),\n",
    "    high_intent_events=(\"is_high_intent\", \"sum\"),\n",
    "    last_event_ts=(\"timestamp\", \"max\"),\n",
    ").reset_index()\n",
    "\n",
    "total_sessions = (events_df[events_df[\"event\"]==\"ACTION_LOGIN\"].groupby(\"user_id\").size().reset_index(name=\"total_sessions\"))\n",
    "\n",
    "engagement_core[\"events_per_active_day\"] = (\n",
    "    engagement_core[\"total_events\"] / engagement_core[\"active_days\"].clip(lower=1)\n",
    ")\n",
    "engagement_core[\"high_intent_ratio\"] = (\n",
    "    engagement_core[\"high_intent_events\"] / engagement_core[\"total_events\"].clip(lower=1)\n",
    ")\n",
    "engagement_core[\"days_since_last_event\"] = (\n",
    "    last_ts - engagement_core[\"last_event_ts\"]\n",
    ").dt.days\n",
    "\n",
    "key_event_counts = (\n",
    "    events_df[events_df[\"event\"].isin(high_intent_events)]\n",
    "    .pivot_table(index=\"user_id\", columns=\"event\", values=\"timestamp\", aggfunc=\"count\", fill_value=0)\n",
    "    .add_prefix(\"event_\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "engagement_features = (\n",
    "    engagement_core\n",
    "    .merge(total_sessions, on=\"user_id\", how=\"left\")\n",
    "    .merge(key_event_counts, on=\"user_id\", how=\"left\")\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "logging.debug(f\"\\n{engagement_features.describe(include='all')}\")\n",
    "logging.debug(f\"\\n{engagement_features.head(10)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b106d1d6",
   "metadata": {},
   "source": [
    "#### Promotion (Voucher Usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9cb9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "logging.info(\"--- Starting Voucher Feature Engineering (Group Part) ---\")\n",
    "\n",
    "try:\n",
    "    vouchers_df = pd.read_csv(\"./original_data/vouchers.csv\")\n",
    "    # 提取所需字段，不修改原始文件\n",
    "    # 假设 'total_discount' 是固定折扣金额，'date_created' 用于计算时效性\n",
    "    vouchers_meta = vouchers_df[['id', 'total_discount', 'date_created']].rename(\n",
    "        columns={'id': 'voucher_id', 'total_discount': 'discount_val'}\n",
    "    )\n",
    "    vouchers_meta['discount_val'] = vouchers_meta['discount_val'].fillna(0)\n",
    "    vouchers_meta['date_created'] = pd.to_datetime(vouchers_meta['date_created'])\n",
    "except FileNotFoundError:\n",
    "    logging.error(\"vouchers.csv not found!\")\n",
    "    raise\n",
    "\n",
    "# 2. 基础关联：Orders + Applications + Vouchers\n",
    "# 严守不改名原则：Orders(id) <-> Applications(order_id)\n",
    "promo_merged = orders_clean_df[['id', 'user_id', 'total_incl_tax']].merge(\n",
    "    voucher_applications_clean_df[['order_id', 'voucher_id', 'created']], \n",
    "    left_on='id', \n",
    "    right_on='order_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 关联 Voucher 详情\n",
    "promo_merged = promo_merged.merge(vouchers_meta, on='voucher_id', how='left')\n",
    "\n",
    "# 3. 计算订单级指标\n",
    "promo_merged['has_voucher'] = promo_merged['voucher_id'].notna().astype(int)\n",
    "promo_merged['savings'] = np.where(promo_merged['has_voucher'] == 1, promo_merged['discount_val'], 0)\n",
    "\n",
    "# 计算 lag_days (领券/用券 滞后天数): 使用时间(created) - 发布时间(date_created)\n",
    "promo_merged['created'] = pd.to_datetime(promo_merged['created'])\n",
    "promo_merged['lag_days'] = (promo_merged['created'] - promo_merged['date_created']).dt.days\n",
    "\n",
    "# 4. 用户级聚合 (User Aggregation)\n",
    "voucher_stats = promo_merged.groupby('user_id').agg(\n",
    "    total_orders=('id', 'count'),\n",
    "    voucher_orders_count=('has_voucher', 'sum'),\n",
    "    total_savings=('savings', 'sum'),\n",
    "    total_revenue=('total_incl_tax', 'sum'),\n",
    "    unique_vouchers_used=('voucher_id', 'nunique'), # 进阶：用过几种不同的券\n",
    "    avg_voucher_lag_days=('lag_days', 'mean')       # 进阶：平均响应天数\n",
    ").reset_index()\n",
    "\n",
    "# 5. 计算比率特征\n",
    "voucher_stats['voucher_usage_rate'] = voucher_stats['voucher_orders_count'] / voucher_stats['total_orders']\n",
    "voucher_stats['discount_savings_ratio'] = voucher_stats.apply(\n",
    "    lambda x: x['total_savings'] / x['total_revenue'] if x['total_revenue'] > 0 else 0, axis=1\n",
    ")\n",
    "\n",
    "# 6. 缺失值处理\n",
    "voucher_stats['avg_voucher_lag_days'] = voucher_stats['avg_voucher_lag_days'].fillna(-1)\n",
    "voucher_stats[['voucher_orders_count', 'total_savings', 'unique_vouchers_used']] = \\\n",
    "    voucher_stats[['voucher_orders_count', 'total_savings', 'unique_vouchers_used']].fillna(0)\n",
    "\n",
    "# 7. 输出最终表 (只保留特征列 + user_id)\n",
    "voucher_features = voucher_stats[[\n",
    "    'user_id', \n",
    "    'voucher_orders_count', \n",
    "    'voucher_usage_rate', \n",
    "    'total_savings', \n",
    "    'discount_savings_ratio',\n",
    "    'unique_vouchers_used',\n",
    "    'avg_voucher_lag_days'\n",
    "]]\n",
    "\n",
    "logging.info(f\"Voucher Part Complete. Shape: {voucher_features.shape}\")\n",
    "display(voucher_features.head())\n",
    "# 1. 统计有多少人真正用过券\n",
    "used_count = len(voucher_features[voucher_features['voucher_orders_count'] > 0])\n",
    "print(f\"用过优惠券的用户数量: {used_count}\")\n",
    "print(f\"占比: {used_count / len(voucher_features):.2%}\")\n",
    "\n",
    "# 2. 展示前 5 个用过券的“真实数据”\n",
    "print(\"\\n--- 用过券的用户示例 (非0数据) ---\")\n",
    "display(voucher_features[voucher_features['voucher_orders_count'] > 0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837f0e97",
   "metadata": {},
   "source": [
    "#### Social (Referrals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56442f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "logging.info(\"--- Starting Social Feature Engineering (Group Part) ---\")\n",
    "\n",
    "# 1. 推荐人维度 (Referrer): 统计拉了多少人\n",
    "# 统计 referred_by 出现的次数\n",
    "referrer_stats = user_references_clean_df.groupby('referred_by').size().reset_index(name='num_referred_users')\n",
    "\n",
    "# 2. 被推荐人维度 (Referee): 谁是被拉进来的\n",
    "referee_users_set = set(user_references_clean_df['user_id'].unique())\n",
    "\n",
    "# 3. 进阶时间特征: 注册后多久开始拉人 (Days to First Referral)\n",
    "# 找到每个推荐人的第一次推荐时间\n",
    "first_ref_time = user_references_clean_df.groupby('referred_by')['created'].min().reset_index(name='first_referral_date')\n",
    "first_ref_time['first_referral_date'] = pd.to_datetime(first_ref_time['first_referral_date'])\n",
    "\n",
    "# 4. 合并回用户表 (User Base)\n",
    "# 以 Users 表为基准，因为我们需要 date_signed_up 来计算时间差\n",
    "# 严守不改名原则：Users(id) <-> user_references(referred_by)\n",
    "social_base = users_clean_df[['id', 'date_signed_up']].drop_duplicates()\n",
    "\n",
    "# 合并推荐数量\n",
    "social_base = social_base.merge(\n",
    "    referrer_stats,\n",
    "    left_on='id',\n",
    "    right_on='referred_by',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 合并第一次推荐时间\n",
    "social_base = social_base.merge(\n",
    "    first_ref_time,\n",
    "    left_on='id',\n",
    "    right_on='referred_by',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 5. 计算特征\n",
    "# Feature A: 成功推荐人数 (空值填0)\n",
    "social_base['num_referred_users'] = social_base['num_referred_users'].fillna(0).astype(int)\n",
    "\n",
    "# Feature B: 是否被推荐用户 (0/1)\n",
    "social_base['is_referred_user'] = social_base['id'].apply(lambda x: 1 if x in referee_users_set else 0)\n",
    "\n",
    "# Feature C: 注册到首次推荐的天数差 (Days to First Referral)\n",
    "social_base['date_signed_up'] = pd.to_datetime(social_base['date_signed_up'])\n",
    "social_base['days_to_first_referral'] = (social_base['first_referral_date'] - social_base['date_signed_up']).dt.days\n",
    "\n",
    "# 处理时间差的空值 (没推荐过人 = -1)\n",
    "social_base['days_to_first_referral'] = social_base['days_to_first_referral'].fillna(-1)\n",
    "\n",
    "# 6. 清理列 (删除合并产生的辅助列)\n",
    "cols_to_drop = [c for c in social_base.columns if 'referred_by' in c or 'date_' in c]\n",
    "social_features_clean = social_base.drop(columns=cols_to_drop)\n",
    "\n",
    "# 重命名 id 为 user_id 以便最后统一合并 (可选，如果组长要求保留 id 则不跑这行)\n",
    "social_features = social_features_clean.rename(columns={'id': 'user_id'})\n",
    "\n",
    "logging.info(f\"Social Part Complete. Shape: {social_features.shape}\")\n",
    "display(social_features.head())\n",
    "\n",
    "# 1. 看看有多少“带货王” (成功推荐过别人)\n",
    "koc_df = social_features[social_features['num_referred_users'] > 0]\n",
    "print(f\"成功推荐过他人的用户数: {len(koc_df)}\")\n",
    "\n",
    "# 2. 看看有多少“被安利的人” (通过推荐注册)\n",
    "referee_df = social_features[social_features['is_referred_user'] == 1]\n",
    "print(f\"通过推荐注册的用户数: {len(referee_df)}\")\n",
    "\n",
    "# 3. 展示一下真实的社交数据\n",
    "print(\"\\n--- 社交达人 (KOC) 示例 ---\")\n",
    "display(koc_df.head())\n",
    "\n",
    "print(\"\\n--- 刚注册就拉人的用户 (时间差小) ---\")\n",
    "# 筛选出推荐过人，且时间差不为 -1 的\n",
    "active_referrers = social_features[social_features['days_to_first_referral'] >= 0]\n",
    "display(active_referrers.sort_values('days_to_first_referral').head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c42e4c",
   "metadata": {},
   "source": [
    "#### SKIPPED FEATURES\n",
    "- NOTE: 一个taste的feature可能有用，McKinsey的好像是有一个taste_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1390597",
   "metadata": {},
   "source": [
    "### Combine all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240a9749",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_features = rfm_features.copy()\n",
    "customer_features = customer_features.merge(behavioral_features, on=\"user_id\", how=\"left\")\n",
    "customer_features = customer_features.merge(product_features, on=\"user_id\", how=\"left\")\n",
    "customer_features = customer_features.merge(subscription_features, on=\"user_id\", how=\"left\")\n",
    "customer_features = customer_features.merge(engagement_features, on=\"user_id\", how=\"left\")\n",
    "customer_features = customer_features.merge(voucher_features, on=\"user_id\", how=\"left\")\n",
    "customer_features = customer_features.merge(social_features, on=\"user_id\", how=\"left\")\n",
    "#customer_features = customer_features.merge(taste_features, on=\"user_id\", how=\"left\")\n",
    "\n",
    "\n",
    "customer_features[\"conversion_rate\"] = customer_features.apply(\n",
    "    lambda row: row[\"frequency_orders\"] / row[\"total_sessions\"] if row[\"total_sessions\"] > 0 else 0,\n",
    "    axis = 1,\n",
    ")\n",
    "\n",
    "fill_zero_cols = [\n",
    "\n",
    "]\n",
    "\n",
    "for col in fill_zero_cols:\n",
    "    if col in customer_features.columns:\n",
    "        customer_features[col] = customer_features[col].fillna(0)\n",
    "\n",
    "max_regularity = customer_features[\"order_regularity_std\"].max()\n",
    "\n",
    "if pd.isna(max_regularity):\n",
    "    max_regularity = 999\n",
    "\n",
    "customer_features[\"order_regularity_std\"] = customer_features[\"order_regularity_std\"].fillna(max_regularity)\n",
    "\n",
    "logging.debug(customer_features.columns.tolist())\n",
    "logging.debug(customer_features.head())\n",
    "logging.debug(customer_features.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d07fcc",
   "metadata": {},
   "source": [
    "### Post combination processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30066abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there are values in primary_currency that are NaN, we use the other primary_currency column to fill\n",
    "\n",
    "behavioral = customer_features[\"primary_currency_behavioral\"]\n",
    "subscription = customer_features[\"primary_currency_subscription\"]\n",
    "\n",
    "customer_features[\"primary_currency_behavioral\"] = behavioral.fillna(subscription)\n",
    "customer_features[\"primary_currency_subscription\"] = subscription.fillna(\n",
    "    customer_features[\"primary_currency_behavioral\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2626a6a",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2751c0",
   "metadata": {},
   "source": [
    "### Split numerical and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd940dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numerical and categorical features\n",
    "num_features = customer_features.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_features = customer_features.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "logging.info(f\"Numerical features ({len(num_features)}): {num_features}\")\n",
    "logging.debug(f\"Categorical features ({len(cat_features)}): {cat_features}\")\n",
    "\n",
    "# Detailed summary for numerical features\n",
    "logging.debug(customer_features[num_features].describe())\n",
    "\n",
    "# Check for unique values in categorical features\n",
    "for col in cat_features:\n",
    "    logging.debug(f\"{col}: {customer_features[col].nunique()} unique values\")\n",
    "\n",
    "\n",
    "\n",
    "# Special consideration for primary currency mismatch\n",
    "# 1) Boolean flag per row\n",
    "customer_features[\"currency_mismatch\"] = (\n",
    "    customer_features[\"primary_currency_behavioral\"]\n",
    "    != customer_features[\"primary_currency_subscription\"]\n",
    ")\n",
    "\n",
    "# 2) Inspect any mismatches\n",
    "mismatched = customer_features[customer_features[\"currency_mismatch\"]]\n",
    "\n",
    "print(f\"Mismatched customers: {len(mismatched)}\")\n",
    "print(mismatched[[\"user_id\", \"primary_currency_behavioral\", \"primary_currency_subscription\"]].head())\n",
    "print(customer_features.groupby(\"primary_currency_behavioral\").count()[\"user_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1913dd",
   "metadata": {},
   "source": [
    "### Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19334b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing values percentage\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing_Count': customer_features.isnull().sum(),\n",
    "    'Missing_Percentage': (customer_features.isnull().sum() / len(customer_features)) * 100\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "print(\"Missing Values Summary:\")\n",
    "print(missing_summary[missing_summary['Missing_Count'] > 0])\n",
    "\n",
    "# Visualize missing values pattern\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(customer_features.isnull(), cbar=True, yticklabels=False, cmap='viridis')\n",
    "plt.title('Missing Values Pattern')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245fb081",
   "metadata": {},
   "source": [
    "### Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59856f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_summary = {}\n",
    "for col in num_features:\n",
    "    Q1 = customer_features[col].quantile(0.25)\n",
    "    Q3 = customer_features[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = customer_features[(customer_features[col] < lower_bound) | (customer_features[col] > upper_bound)][col]\n",
    "    outlier_percentage = (len(outliers) / len(customer_features)) * 100\n",
    "    outlier_summary[col] = outlier_percentage\n",
    "\n",
    "outlier_df = pd.DataFrame.from_dict(outlier_summary, orient='index', \n",
    "                                   columns=['Outlier_Percentage'])\n",
    "print(\"Outlier Summary (IQR method):\")\n",
    "print(outlier_df.sort_values('Outlier_Percentage', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b2928a",
   "metadata": {},
   "source": [
    "### Distribution of key customer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213b622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(10, 15))\n",
    "fig.suptitle(\"Distribution of Key Customer Features\", fontsize=15, fontweight=\"bold\")\n",
    "\n",
    "# Recency\n",
    "axes[0, 1].hist(customer_features[\"recency_days\"], bins=50, edgecolor=\"black\")\n",
    "axes[0, 1].set_title(\"Recency (Days since last order)\")\n",
    "axes[0, 1].set_xlabel(\"Days\")\n",
    "axes[0, 1].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Frequency\n",
    "axes[0, 1].hist(customer_features[\"frequency_orders\"], bins=50, edgecolor=\"black\")\n",
    "axes[0, 1].set_title(\"Frequency (Numbers of Orders)\")\n",
    "axes[0, 1].set_xlabel(\"Number of Orders\")\n",
    "axes[0, 1].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Monetary\n",
    "axes[0, 2].hist(customer_features[\"monetary_total\"], bins=50, edgecolor=\"black\")\n",
    "axes[0, 2].set_title(\"Monetary (Total Spend)\")\n",
    "axes[0, 2].set_xlabel(\"Number Spend ($)\")\n",
    "axes[0, 2].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Subscription status\n",
    "# subscription_counts = customer_features[\"has_subscription\"].value_counts()\n",
    "customer_features[\"has_subscription\"] = (customer_features[\"active_subscriptions\"].fillna(0) > 0).astype(int)\n",
    "subscription_counts = customer_features[\"has_subscription\"].value_counts()\n",
    "axes[1, 0].bar([\"No Subscription\", \"Has Subscription\"], subscription_counts.values)\n",
    "axes[1, 0].set_title(\"Subscription Status Distribution\")\n",
    "axes[1, 0].set_ylabel(\"Number of Customers\")\n",
    "\n",
    "# Engagement\n",
    "axes[1, 1].hist(customer_features[\"total_events\"], bins=50, edgecolor=\"black\")\n",
    "axes[1, 1].set_title(\"Total Engagement Events\")\n",
    "axes[1, 1].set_xlabel(\"Number of Events\")\n",
    "axes[1, 1].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Voucher usage\n",
    "#voucher_counts = (customer_features[\"is_voucher_user\"] > 0).value_counts()\n",
    "voucher_counts = (customer_features[\"voucher_orders_count\"].fillna(0) > 0).value_counts()\n",
    "axes[1, 2].bar([\"No Vouchers\", \"Used Vouchers\"], voucher_counts.values)\n",
    "axes[1, 2].set_title(\"Voucher Usage Distribution\")\n",
    "axes[1, 2].set_ylabel(\"Number of Customers\")\n",
    "\n",
    "# Taste Preferences,   这个地方我改了，注意  注意  注意\n",
    "customer_features['has_preferences'] = customer_features['user_id'].isin(preferences_clean_df['user_id']).astype(int)\n",
    "taste_counts = (customer_features[\"has_preferences\"] >0).value_counts()\n",
    "axes[2, 2].bar([\"No Preferences\", \"Has Preferences\"], taste_counts.values)\n",
    "axes[2, 2].set_title(\"Taste Preferences Set\")\n",
    "axes[2, 2].set_ylabel(\"Number of Customers\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2d513c",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b666bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 14))\n",
    "\n",
    "#这里新加了selct_dtypes去取数值类型，因为只能计算数值类型的相关性\n",
    "\n",
    "numeric_features = customer_features.select_dtypes(include=[np.number]).drop(\"user_id\", axis=1, errors=\"ignore\")\n",
    "\n",
    "correlation_matrix = numeric_features.corr()\n",
    "sns.heatmap(correlation_matrix, annot=False, fmt=\".2f\", cmap=\"coolwarm\", center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.0})\n",
    "plt.title(\"Feature Correlation Matrix\", fontsize=14, fontweight=\"bold\", pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff06987b",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5835f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_features = customer_features.drop([\"user_id\", \"primary_currency\"], axis=1, errors=\"ignore\")\n",
    "\n",
    "logging.debug(f\"Features for clustering: {len(clustering_features.columns)} features\")\n",
    "logging.debug(f\"Shape: {clustering_features.shape}\")\n",
    "\n",
    "missing_count = clustering_features.isnull().sum().sum()\n",
    "logging.debug(f\"Missing values: {missing_count}\")\n",
    "\n",
    "if missing_count > 0:\n",
    "    logging.warning(\"Found missing values\")\n",
    "    # 这里我也改了，非数据和数据类型不同的处理方式  注意 注意  注意\n",
    "    # 只对数值型列填充中位数\n",
    "    num_cols = clustering_features.select_dtypes(include=[np.number]).columns\n",
    "    cluster_features = clustering_features.copy()\n",
    "    cluster_features[num_cols] = cluster_features[num_cols].fillna(cluster_features[num_cols].median())\n",
    "    # 对非数值型列用众数填充\n",
    "    non_num_cols = clustering_features.select_dtypes(exclude=[np.number]).columns\n",
    "    for col in non_num_cols:\n",
    "        mode_val = clustering_features[col].mode()\n",
    "        if not mode_val.empty:\n",
    "            cluster_features[col] = cluster_features[col].fillna(mode_val[0])\n",
    "        else:\n",
    "            cluster_features[col] = cluster_features[col].fillna(\"unknown\")\n",
    "    logging.warning(\"Missing values filled with median/mode\")\n",
    "else:\n",
    "    cluster_features = clustering_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb2536",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#注意这里只能是数据类型  所以又改了  注意  注意  注意\n",
    "numeric_cluster_features = cluster_features.select_dtypes(include=[np.number])\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(numeric_cluster_features)\n",
    "\n",
    "logging.debug(\"Clutering Features scaled using StandardScaler\")\n",
    "logging.debug(f\"Scaled features shape: {features_scaled.shape}\")\n",
    "logging.debug(f\"Scaled features mean: {features_scaled.mean():.4f}\") # Should be near 0\n",
    "logging.debug(f\"Scaled features std: {features_scaled.std():.4f}\") # Should be near 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d0ebfc",
   "metadata": {},
   "source": [
    "### Testing Different Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc8b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1\n",
    "inertias = []\n",
    "silhouette_scores_list = []\n",
    "k_range = range(2, 11)\n",
    "\n",
    "for k in k_range:\n",
    "    logging.debug(f\"Testing k={k}\")\n",
    "\n",
    "    k_means = KMeans(n_clusters=k, random_state=random_state, n_init=10)\n",
    "    k_means.fit(features_scaled)\n",
    "\n",
    "    inertias.append(k_means.inertia_)\n",
    "    silhouette_scores_list.append(silhouette_score(features_scaled, k_means.labels_))\n",
    "\n",
    "    logging.info(f\"K={k} | Inertia={inertias[-1]:.3f} | Silhouette: {silhouette_scores_list[-1]:.3f}\")\n",
    "\n",
    "\n",
    "plt, axes = plt.subplots(1, 2, figsize=(14, 9))\n",
    "\n",
    "axes[1].plot(k_range, inertias, \"ro-\", linewidth=2, markersize=3)\n",
    "axes[1].set_xlabel(\"Number of Clusters (k)\", fontsize=12)\n",
    "axes[1].set_ylabel(\"Inertia (Within-cluster sum of squares)\", fontsize=12)\n",
    "axes[0].set_title(\"Elbow method\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(k_range, silhouette_scores_list, \"ro-\", linewidth=2, markersize=3)\n",
    "axes[1].set_xlabel(\"Number of Clusters (k)\", fontsize=12)\n",
    "axes[1].set_ylabel(\"Silhouette Score\", fontsize=12)\n",
    "axes[1].set_title(\"Silhouette Score Method\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817fb088",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_k = 4\n",
    "\n",
    "logging.debug(f\"Fitting K-Means with k={optimal_k}\")\n",
    "\n",
    "k_means_final = KMeans(n_clusters=optimal_k, random_state=random_state, n_init=10)\n",
    "cluster_labels = k_means_final.fit_predict(features_scaled)\n",
    "\n",
    "customer_features[\"cluster\"] = cluster_labels\n",
    "\n",
    "logging.info(f\"Final inertia: {k_means_final.inertia_:.2f}\")\n",
    "logging.info(f\"Silhouette Score: {silhouette_score(features_scaled, cluster_labels):.3f}\")\n",
    "\n",
    "cluster_counts = customer_features[\"cluster\"].value_counts().sort_index()\n",
    "for cluster_id, count in cluster_counts.items():\n",
    "    percentage = (count / len(customer_features)) * 100\n",
    "    logging.info(f\"Cluster {cluster_id}: {count} customers ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2c6cb4",
   "metadata": {},
   "source": [
    "## Cluster Analysis and Profiling\n",
    "- 视频有点难看，代码很多，我懒得再抄了\n",
    "- 而且我们模型不会一样\n",
    "- 可以自己研究一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0fe909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要先做好一个cluster_profiles\n",
    "# 让后这个是McKinsey他们的定义，只是参考\n",
    "\n",
    "def interpret_cluster(cluster_id, profile):\n",
    "    row = profile.loc[cluster_id]\n",
    "\n",
    "    high_freq = row[\"frequency_orders\"] > cluster_profiles[\"frequency_orders\"].median()\n",
    "    high_monetary = row[\"monetary_total\"] > cluster_profiles[\"monetary_total\"].median()\n",
    "    low_recency = row[\"recency_days\"] < cluster_profile[\"recency_days\"].median()\n",
    "    has_sub = row[\"has_subsciption\"] > 0.5\n",
    "    high_engagement = row[\"total_events\"] > cluster_profiles[\"total_events\"].median()\n",
    "\n",
    "    if high_freq and high_monetary and has_sub:\n",
    "        name = \"VIP Champions\"\n",
    "        description = \"High value loyal customers with active subscriptions\"\n",
    "    elif high_freq and low_recency:\n",
    "        name = \"Loyal Regulars\"\n",
    "        description = \"Frequent buyers who purchase regularly\"\n",
    "    elif not low_recency and not high_freq:\n",
    "        name = \"At-Risk / Hibernating\"\n",
    "        description = \"Previously active but haven't purchased recently\"\n",
    "    else:\n",
    "        name = \"Casual Explorers\"\n",
    "        description = \"Infrequent buyers, potential growth\"\n",
    "    return name, description\n",
    "\n",
    "for cluster_id in range(optimal_k):\n",
    "    name, description = interpret_cluster(cluster_id, cluster_profiles)\n",
    "    cluster_names[cluster_id] = name\n",
    "    cluster_descriptions[cluster_id] = description\n",
    "\n",
    "    size = (customer_features[\"cluster\"] == cluster_id).sum()\n",
    "    percentage = (size / len(customer_features)) * 100\n",
    "\n",
    "    revenue_info = revenue_analysis(revenue_analysis[\"cluster\"] == cluster_id).iloc[0]\n",
    "    logging.info(f\"Cluster {cluster_id}: {name}\")\n",
    "    logging.info(f\"Description: {description}\")\n",
    "    logging.info(f\"Size: {size} customers ({percentage:.1f}%)\")\n",
    "    # logging.info(f\"Revenue contribution: {revenue_info[\"total_revenue\"]:.2f} ({revenue_info[\"total_pct\"]:.2f}% of total)\")\n",
    "\n",
    "\n",
    "    row = cluster_profiles.loc[cluster_id]\n",
    "    # log out avg recency, avg frequency, avg total spend, avg order value\n",
    "    # subscription rate, avg engagement events, voucher usage rate\n",
    "    # referral rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe6bb29",
   "metadata": {},
   "source": [
    "## Business Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdd46c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = []\n",
    "\n",
    "for _, rev_row in revenue_analysis.iterrows():\n",
    "    cluster_id = int(rev_row[\"cluster\"])\n",
    "    row = cluster_profiles.loc[cluster_id]\n",
    "    name = cluster_names[cluster_id]\n",
    "    descriptions = cluster_descriptions[cluster_id]\n",
    "    size = int(rev_row[\"customer_count\"])\n",
    "\n",
    "    strategies = []\n",
    "\n",
    "    if row[\"monetary_total\"] > cluster_profiles[\"monetary_total\"].quantile(0.75):\n",
    "        strategies.append(\"VIP program: Exclusive early access to new products\")\n",
    "        strategies.append(\"Premium Offerings: Introduce limited edition or premium...\")\n",
    "    # something like this...\n",
    "\n",
    "\n",
    "# Also find the priority of each cluster and show why(size%, revenue contribution, avg revenue per customer)\n",
    "# sort by this priority"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
